{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Thoery Qs."
      ],
      "metadata": {
        "id": "zkBgU1KSpwiT"
      },
      "id": "zkBgU1KSpwiT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. What does R-squared represent in a regression model?\n",
        "R-squared represents the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. What are the assumptions of linear regression?\n",
        "- Linearity\n",
        "- Independence\n",
        "- Homoscedasticity (constant variance of errors)\n",
        "- Normality of residuals\n",
        "- No multicollinearity\n",
        "\n",
        "---\n",
        "\n",
        "### 3. What is the difference between R-squared and Adjusted R-squared?\n",
        "- **R-squared** increases with more predictors.\n",
        "- **Adjusted R-squared** adjusts for the number of predictors, penalizing unnecessary ones.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Why do we use Mean Squared Error (MSE)?\n",
        "MSE measures the average squared difference between actual and predicted values, helping evaluate model accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. What does an Adjusted R-squared value of 0.85 indicate?\n",
        "It means that 85% of the variance in the dependent variable is explained by the model, adjusting for the number of predictors.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. How do we check for normality of residuals in linear regression?\n",
        "- Histogram or Q-Q plot of residuals\n",
        "- Shapiro-Wilk test\n",
        "- Kolmogorov-Smirnov test\n",
        "\n",
        "---\n",
        "\n",
        "### 7. What is multicollinearity, and how does it impact regression?\n",
        "Multicollinearity occurs when independent variables are highly correlated, making coefficient estimates unstable and less interpretable.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. What is Mean Absolute Error (MAE)?\n",
        "MAE is the average absolute difference between actual and predicted values. It is less sensitive to outliers than MSE.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. What are the benefits of using an ML pipeline?\n",
        "- Streamlined preprocessing and modeling\n",
        "- Reduces code duplication\n",
        "- Ensures reproducibility\n",
        "- Facilitates parameter tuning and deployment\n",
        "\n",
        "---\n",
        "\n",
        "### 10. Why is RMSE considered more interpretable than MSE?\n",
        "RMSE is in the same unit as the target variable, unlike MSE which is in squared units.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. What is pickling in Python, and how is it useful in ML?\n",
        "Pickling serializes Python objects to a byte stream, useful for saving trained models and reloading them without retraining.\n",
        "\n",
        "---\n",
        "\n",
        "### 12. What does a high R-squared value mean?\n",
        "It indicates a strong fit between the model and the data, i.e., a high percentage of variance is explained by the model.\n",
        "\n",
        "---\n",
        "\n",
        "### 13. What happens if linear regression assumptions are violated?\n",
        "It can lead to biased or inefficient estimates, unreliable hypothesis tests, and poor predictive performance.\n",
        "\n",
        "---\n",
        "\n",
        "### 14. How can we address multicollinearity in regression?\n",
        "- Remove highly correlated predictors\n",
        "- Use dimensionality reduction (e.g., PCA)\n",
        "- Apply regularization methods like Ridge or Lasso\n",
        "\n",
        "---\n",
        "\n",
        "### 15. How can feature selection improve model performance in regression analysis?\n",
        "Feature selection removes irrelevant or redundant features, reducing overfitting and improving model interpretability and performance.\n",
        "\n",
        "---\n",
        "\n",
        "### 16. How is Adjusted R-squared calculated?\n",
        "Adjusted R² = 1 - [(1 - R²) * (n - 1)/(n - k - 1)], where `n` is number of observations and `k` is number of predictors.\n",
        "\n",
        "---\n",
        "\n",
        "### 17. Why is MSE sensitive to outliers?\n",
        "Because it squares the error term, outliers have a disproportionately large impact on MSE.\n",
        "\n",
        "---\n",
        "\n",
        "### 18. What is the role of homoscedasticity in linear regression?\n",
        "Homoscedasticity (equal error variance) ensures reliable coefficient estimates and valid hypothesis testing.\n",
        "\n",
        "---\n",
        "\n",
        "### 19. What is Root Mean Squared Error (RMSE)?\n",
        "RMSE is the square root of MSE. It measures the average magnitude of prediction errors.\n",
        "\n",
        "---\n",
        "\n",
        "### 20. Why is pickling considered risky?\n",
        "Pickling can execute arbitrary code during loading, leading to security vulnerabilities if loading untrusted data.\n",
        "\n",
        "---\n",
        "\n",
        "### 21. What alternatives exist to pickling for saving ML models?\n",
        "- Joblib (optimized for NumPy arrays)\n",
        "- ONNX (Open Neural Network Exchange)\n",
        "- JSON (for lightweight, secure storage)\n",
        "\n",
        "---\n",
        "\n",
        "### 22. What is heteroscedasticity, and why is it a problem?\n",
        "Heteroscedasticity is non-constant variance of residuals. It violates regression assumptions and leads to inefficient estimates.\n",
        "\n",
        "---\n",
        "\n",
        "### 23. How can interaction terms enhance a regression model's predictive power?\n",
        "Interaction terms capture combined effects of features, improving model flexibility and accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "VNa1ODiTpvq4"
      },
      "id": "VNa1ODiTpvq4"
    },
    {
      "cell_type": "markdown",
      "id": "c50f5d0a",
      "metadata": {
        "id": "c50f5d0a"
      },
      "source": [
        "# Practical Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f9b3b5",
      "metadata": {
        "id": "c5f9b3b5"
      },
      "source": [
        "## Task 1: Visualize Residuals for Multiple Linear Regression using Seaborn's 'diamonds' Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f076c4",
      "metadata": {
        "id": "71f076c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "diamonds = diamonds.select_dtypes(include=[np.number]).dropna()\n",
        "\n",
        "X = diamonds.drop(columns=['price'])\n",
        "y = diamonds['price']\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "predictions = model.predict(X)\n",
        "residuals = y - predictions\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347b4ba1",
      "metadata": {
        "id": "347b4ba1"
      },
      "source": [
        "## Task 2: Calculate MSE, MAE, and RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db1cfe4",
      "metadata": {
        "id": "7db1cfe4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "mse = mean_squared_error(y, predictions)\n",
        "mae = mean_absolute_error(y, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"RMSE: {rmse}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b30287",
      "metadata": {
        "id": "b4b30287"
      },
      "source": [
        "## Task 3: Check Assumptions of Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af044323",
      "metadata": {
        "id": "af044323"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Linearity\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(predictions, y)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Linearity Check')\n",
        "plt.show()\n",
        "\n",
        "# Homoscedasticity\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(predictions, residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('Residuals Plot')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Multicollinearity\n",
        "corr_matrix = X.drop(columns='const').corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d7a1a4",
      "metadata": {
        "id": "46d7a1a4"
      },
      "source": [
        "## Task 4: . Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the performance of different regression models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0734dd5a",
      "metadata": {
        "id": "0734dd5a"
      },
      "outputs": [],
      "source": [
        "# Code for Task 4 goes here\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"Score:\", pipeline.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcd4c9e",
      "metadata": {
        "id": "8bcd4c9e"
      },
      "source": [
        "## Task 5 :  Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and R-squared score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e12a706",
      "metadata": {
        "id": "3e12a706"
      },
      "outputs": [],
      "source": [
        "# Code for Task 5 goes here\n",
        "model = LinearRegression()\n",
        "model.fit(X[['carat']], y)\n",
        "print(\"Coefficient:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"R^2 Score:\", model.score(X[['carat']], y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e137e142",
      "metadata": {
        "id": "e137e142"
      },
      "source": [
        "## Task 6 : Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using simple linear regression and visualizes the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a810f702",
      "metadata": {
        "id": "a810f702"
      },
      "outputs": [],
      "source": [
        "# Code for Task 6 goes here\n",
        "df = sns.load_dataset(\"tips\")\n",
        "X = df[['total_bill']]\n",
        "y = df['tip']\n",
        "model = LinearRegression().fit(X, y)\n",
        "sns.regplot(x='total_bill', y='tip', data=df)\n",
        "plt.title(\"Tip vs Total Bill\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09209508",
      "metadata": {
        "id": "09209508"
      },
      "source": [
        "## Task 7 :  Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the model to predict new values and plot the data points along with the regression line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cfa9415",
      "metadata": {
        "id": "2cfa9415"
      },
      "outputs": [],
      "source": [
        "# Code for Task 7 goes here\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10)\n",
        "model = LinearRegression().fit(X, y)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7507096",
      "metadata": {
        "id": "e7507096"
      },
      "source": [
        "## Task 8 : Write a Python script that pickles a trained linear regression model and saves it to a file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7364a3",
      "metadata": {
        "id": "ca7364a3"
      },
      "outputs": [],
      "source": [
        "# Code for Task 8 goes here\n",
        "import pickle\n",
        "\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642a7525",
      "metadata": {
        "id": "642a7525"
      },
      "source": [
        "## Task 9 : Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the regression curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd37cfaa",
      "metadata": {
        "id": "cd37cfaa"
      },
      "outputs": [],
      "source": [
        "# Code for Task 9 goes here\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X[['carat']])\n",
        "model = LinearRegression().fit(X_poly, y)\n",
        "y_pred = model.predict(X_poly)\n",
        "\n",
        "plt.scatter(X['carat'], y)\n",
        "plt.plot(X['carat'], y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c779dfd",
      "metadata": {
        "id": "8c779dfd"
      },
      "source": [
        "## Task 10 : Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear regression model to the data. Print the model's coefficient and intercept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a24c1f",
      "metadata": {
        "id": "27a24c1f"
      },
      "outputs": [],
      "source": [
        "# Code for Task 10 goes here\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=15)\n",
        "model = LinearRegression().fit(X, y)\n",
        "print(\"Coefficient:\", model.coef_, \"Intercept:\", model.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c845846f",
      "metadata": {
        "id": "c845846f"
      },
      "source": [
        "## Task 11 :  Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and compares their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c861c432",
      "metadata": {
        "id": "c861c432"
      },
      "outputs": [],
      "source": [
        "# Code for Task 11 goes here\n",
        "for d in [1, 2, 3, 4]:\n",
        "    poly = PolynomialFeatures(degree=d)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model = LinearRegression().fit(X_poly, y)\n",
        "    print(f\"Degree {d}, R^2 Score: {model.score(X_poly, y)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940e7666",
      "metadata": {
        "id": "940e7666"
      },
      "source": [
        "## Task 12 : Write a Python script that fits a simple linear regression model with two features and prints the model's coefficients, intercept, and R-squared score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b20d6e4",
      "metadata": {
        "id": "1b20d6e4"
      },
      "outputs": [],
      "source": [
        "# Code for Task 12 goes here\n",
        "model = LinearRegression().fit(X[['carat', 'depth']], y)\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"R^2:\", model.score(X[['carat', 'depth']], y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad86fd11",
      "metadata": {
        "id": "ad86fd11"
      },
      "source": [
        "## Task 13 : Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the regression line along with the data points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd0c91ba",
      "metadata": {
        "id": "dd0c91ba"
      },
      "outputs": [],
      "source": [
        "# Code for Task 13 goes here\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=20)\n",
        "model = LinearRegression().fit(X, y)\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, model.predict(X), color='green')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43239288",
      "metadata": {
        "id": "43239288"
      },
      "source": [
        "## Task 14 : 14. Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset with multiple features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2546ba",
      "metadata": {
        "id": "2a2546ba"
      },
      "outputs": [],
      "source": [
        "# Code for Task 14 goes here\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X = df[[\"carat\", \"depth\", \"table\"]]\n",
        "X = sm.add_constant(X)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(vif_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5272cae1",
      "metadata": {
        "id": "5272cae1"
      },
      "source": [
        "## Task 15 : 15. Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a polynomial regression model, and plots the regression curve.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698b9846",
      "metadata": {
        "id": "698b9846"
      },
      "outputs": [],
      "source": [
        "# Code for Task 15 goes here\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_poly = poly.fit_transform(X[['carat']])\n",
        "model = LinearRegression().fit(X_poly, y)\n",
        "plt.scatter(X['carat'], y)\n",
        "plt.plot(X['carat'], model.predict(X_poly), color='orange')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c9c922",
      "metadata": {
        "id": "79c9c922"
      },
      "source": [
        "## Task 16 : Write a Python script that creates a machine learning pipeline with data standardization and a multiple linear regression model, and prints the R-squared score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e963e4",
      "metadata": {
        "id": "70e963e4"
      },
      "outputs": [],
      "source": [
        "# Code for Task 16 goes here\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('reg', LinearRegression())\n",
        "])\n",
        "pipeline.fit(X, y)\n",
        "print(\"R^2 Score:\", pipeline.score(X, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3048932b",
      "metadata": {
        "id": "3048932b"
      },
      "source": [
        "## Task 17 : Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the regression curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d0ea1c0",
      "metadata": {
        "id": "6d0ea1c0"
      },
      "outputs": [],
      "source": [
        "# Code for Task 17 goes here\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X[['carat']])\n",
        "model = LinearRegression().fit(X_poly, y)\n",
        "plt.scatter(X['carat'], y)\n",
        "plt.plot(X['carat'], model.predict(X_poly), color='purple')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a934188",
      "metadata": {
        "id": "3a934188"
      },
      "source": [
        "## Task 18 :  Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print the R-squared score and model coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7579794d",
      "metadata": {
        "id": "7579794d"
      },
      "outputs": [],
      "source": [
        "# Code for Task 18 goes here\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10)\n",
        "model = LinearRegression().fit(X, y)\n",
        "print(\"R^2:\", model.score(X, y))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d89cee",
      "metadata": {
        "id": "f3d89cee"
      },
      "source": [
        "## Task 19 : Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the data points along with the regression line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758d552d",
      "metadata": {
        "id": "758d552d"
      },
      "outputs": [],
      "source": [
        "# Code for Task 19 goes here\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10)\n",
        "model = LinearRegression().fit(X, y)\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, model.predict(X), color='black')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5816a176",
      "metadata": {
        "id": "5816a176"
      },
      "source": [
        "## Task 20 : Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's Rsquared score and coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f4b16a",
      "metadata": {
        "id": "d6f4b16a"
      },
      "outputs": [],
      "source": [
        "# Code for Task 20 goes here\n",
        "X, y = make_regression(n_samples=100, n_features=3, noise=5)\n",
        "model = LinearRegression().fit(X, y)\n",
        "print(\"R^2:\", model.score(X, y))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837c2e31",
      "metadata": {
        "id": "837c2e31"
      },
      "source": [
        "## Task 21 : Write a Python script that demonstrates how to serialize and deserialize machine learning models using joblib instead of pickling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca70a57a",
      "metadata": {
        "id": "ca70a57a"
      },
      "outputs": [],
      "source": [
        "# Code for Task 21 goes here\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'model.joblib')\n",
        "loaded_model = joblib.load('model.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d30b73d4",
      "metadata": {
        "id": "d30b73d4"
      },
      "source": [
        "## Task 22 : Write a Python script to perform linear regression with categorical features using one-hot encoding. Use the Seaborn 'tips' dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bcf978c",
      "metadata": {
        "id": "1bcf978c"
      },
      "outputs": [],
      "source": [
        "# Code for Task 22 goes here\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df = pd.get_dummies(df, columns=[\"sex\", \"smoker\", \"day\", \"time\"], drop_first=True)\n",
        "X = df.drop(\"tip\", axis=1)\n",
        "y = df[\"tip\"]\n",
        "model = LinearRegression().fit(X, y)\n",
        "print(\"R^2:\", model.score(X, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8251c237",
      "metadata": {
        "id": "8251c237"
      },
      "source": [
        "## Task 23 : Compare Ridge Regression with Linear Regression on a synthetic dataset and print the coefficients and Rsquared score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3efbfb6",
      "metadata": {
        "id": "f3efbfb6"
      },
      "outputs": [],
      "source": [
        "# Code for Task 23 goes here\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=2, noise=15)\n",
        "lr = LinearRegression().fit(X, y)\n",
        "ridge = Ridge(alpha=1).fit(X, y)\n",
        "\n",
        "print(\"Linear R^2:\", lr.score(X, y))\n",
        "print(\"Ridge R^2:\", ridge.score(X, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c56762",
      "metadata": {
        "id": "25c56762"
      },
      "source": [
        "## Task 24 : Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1347085b",
      "metadata": {
        "id": "1347085b"
      },
      "outputs": [],
      "source": [
        "# Code for Task 24 goes here\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=2, noise=10)\n",
        "model = LinearRegression()\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-validated scores:\", scores)\n",
        "print(\"Mean score:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9d4d8a",
      "metadata": {
        "id": "0b9d4d8a"
      },
      "source": [
        "## Task 25 : Write a Python script that compares polynomial regression models of different degrees and prints the Rsquared score for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e57022",
      "metadata": {
        "id": "32e57022"
      },
      "outputs": [],
      "source": [
        "# Code for Task 25 goes here\n",
        "for degree in range(1, 5):\n",
        "    poly = PolynomialFeatures(degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model = LinearRegression().fit(X_poly, y)\n",
        "    print(f\"Degree {degree} R^2: {model.score(X_poly, y)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}